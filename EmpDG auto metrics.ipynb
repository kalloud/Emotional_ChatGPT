{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14ded88-6411-4556-9a83-d7f758665243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sacrebleu\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from math import exp\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9178a7-5824-44b4-a756-896eeac37097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Electra Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraClassifier: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraClassifier were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electra Classifier is ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Electra Classifier...\")\n",
    "from electra_classifier import *\n",
    "\n",
    "best_model_path = \"electra_cls/lightning_logs/version_18/checkpoints/epoch=9-step=3629.ckpt\"\n",
    "emotion_categories = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "       'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "       'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "       'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "       'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
    "\n",
    "MODEL_NAME = \"google/electra-base-discriminator\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "trained_model = EmotionClassifier.load_from_checkpoint(\n",
    "    # trainer.checkpoint_callback.best_model_path,\n",
    "    best_model_path,\n",
    "    n_classes=len(emotion_categories)\n",
    ")\n",
    "\n",
    "def predict_emotion_and_probability(text):\n",
    "    encoding = tokenizer(\n",
    "          text,\n",
    "          max_length=64, \n",
    "          truncation=True,\n",
    "          padding=\"max_length\",\n",
    "          add_special_tokens=True,\n",
    "          return_token_type_ids=False,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors=\"pt\"\n",
    "      )\n",
    "    outputs = trained_model(**encoding)\n",
    "    probabilities = list(torch.softmax(outputs, dim=-1).detach().numpy().flatten())\n",
    "    emotion_idx = torch.argmax(outputs, dim=-1).item() \n",
    "    predicted_emotion = emotion_categories[emotion_idx]\n",
    "\n",
    "    emotion_categories_list = list(emotion_categories)\n",
    "    probabilities, emotion_categories_list = zip(*sorted(zip(probabilities, emotion_categories_list)))\n",
    "    probabilities = probabilities[::-1]\n",
    "    emotion_categories_list = emotion_categories_list[::-1]\n",
    "    emotion_probability = round(100*probabilities[0], 2)#:.2f\n",
    "\n",
    "    return predicted_emotion, emotion_probability\n",
    "\n",
    "print(\"Electra Classifier is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eff598-45db-4462-920b-efbe15e622d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('joy', 98.35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"I do! I was so happy when I opened the box and that fat mofo jumped out!\"\n",
    "predict_emotion_and_probability(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974d4fa-2d4d-41e0-b63a-8531e4b49d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1753ab4e-1046-489b-9147-cc90f1729945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer</th>\n",
       "      <th>ref</th>\n",
       "      <th>emoprepend</th>\n",
       "      <th>moel</th>\n",
       "      <th>empDG_woD</th>\n",
       "      <th>empDG</th>\n",
       "      <th>utterance</th>\n",
       "      <th>chatgpt_response_no_emotion</th>\n",
       "      <th>chatgpt_emotional_response</th>\n",
       "      <th>chatgpt_prompt2_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh no , i am so sorry to hear that .</td>\n",
       "      <td>did you suffer any injuries ?</td>\n",
       "      <td>oh no , did they catch them ?</td>\n",
       "      <td>oh no ! i hate spiders !</td>\n",
       "      <td>oh man , that is terrible . i hope you are oka...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry . i am s...</td>\n",
       "      <td>[yeah about 10 years ago i had a horrifying ex...</td>\n",
       "      <td>Wow, that sounds really scary! Have you been a...</td>\n",
       "      <td>(fear, 99.56, I'm sorry to hear about your sca...</td>\n",
       "      <td>That sounds really scary and traumatic, and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that is really nice of them .</td>\n",
       "      <td>yeah i wanted to tell you about the time i was...</td>\n",
       "      <td>i am glad you are not good .</td>\n",
       "      <td>that is good , i am sure you are looking for t...</td>\n",
       "      <td>oh , i am sorry to hear that . i hope you are ...</td>\n",
       "      <td>i am so sorry to hear that . i can not like th...</td>\n",
       "      <td>[well , can you tell me about your experience ...</td>\n",
       "      <td>As an AI language model, I don't really have \"...</td>\n",
       "      <td>(curiosity, 99.7, As an AI language model, I d...</td>\n",
       "      <td>I'm sorry, as an AI language model, I don't ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is a shame . i am glad you got a lot of s...</td>\n",
       "      <td>sorry to hear ! do you have any idea about the...</td>\n",
       "      <td>that is a lot of thing to do that .</td>\n",
       "      <td>that is a good attitude to do .</td>\n",
       "      <td>that is a bummer . i have a lot of people .</td>\n",
       "      <td>oh no ! that is a shame !</td>\n",
       "      <td>[i there , dont know what to do , jst broke up...</td>\n",
       "      <td>Take some time to process your emotions, refle...</td>\n",
       "      <td>(confusion, 95.6, It's okay to feel lost and h...</td>\n",
       "      <td>I'm sorry to hear that, it's completely normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what concert ?</td>\n",
       "      <td>which concert ?</td>\n",
       "      <td>that is awesome ! what band is it ?</td>\n",
       "      <td>that is awesome ! what is it ?</td>\n",
       "      <td>what kind of concert ?</td>\n",
       "      <td>what band is it ?</td>\n",
       "      <td>[i could not wait to go to the concert . , whi...</td>\n",
       "      <td>That's so exciting! Who is performing at the c...</td>\n",
       "      <td>(excitement, 99.32, Awesome, I hope you have a...</td>\n",
       "      <td>I can imagine how excited you must be! Going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am sorry to hear that . i am sure you will b...</td>\n",
       "      <td>ugh , those articles always get me too ... : (...</td>\n",
       "      <td>i am sorry to hear that . i am glad you are no...</td>\n",
       "      <td>i am sorry to hear that . i know how you feel .</td>\n",
       "      <td>oh , i am sorry to hear that . i am sorry to h...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry to hear ...</td>\n",
       "      <td>[i am so sad because i have read an article ab...</td>\n",
       "      <td>I understand why that would make you feel sad,...</td>\n",
       "      <td>(sadness, 99.03, I'm sorry to hear that. It's ...</td>\n",
       "      <td>I'm sorry to hear that. It's a tragic situation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transformer  \\\n",
       "0             oh no , i am so sorry to hear that .     \n",
       "1                    that is really nice of them .     \n",
       "2  that is a shame . i am glad you got a lot of s...   \n",
       "3                                   what concert ?     \n",
       "4  i am sorry to hear that . i am sure you will b...   \n",
       "\n",
       "                                                 ref  \\\n",
       "0                     did you suffer any injuries ?    \n",
       "1  yeah i wanted to tell you about the time i was...   \n",
       "2  sorry to hear ! do you have any idea about the...   \n",
       "3                                   which concert ?    \n",
       "4  ugh , those articles always get me too ... : (...   \n",
       "\n",
       "                                          emoprepend  \\\n",
       "0                    oh no , did they catch them ?     \n",
       "1                     i am glad you are not good .     \n",
       "2              that is a lot of thing to do that .     \n",
       "3              that is awesome ! what band is it ?     \n",
       "4  i am sorry to hear that . i am glad you are no...   \n",
       "\n",
       "                                                moel  \\\n",
       "0                         oh no ! i hate spiders !     \n",
       "1  that is good , i am sure you are looking for t...   \n",
       "2                  that is a good attitude to do .     \n",
       "3                   that is awesome ! what is it ?     \n",
       "4  i am sorry to hear that . i know how you feel .     \n",
       "\n",
       "                                           empDG_woD  \\\n",
       "0  oh man , that is terrible . i hope you are oka...   \n",
       "1  oh , i am sorry to hear that . i hope you are ...   \n",
       "2      that is a bummer . i have a lot of people .     \n",
       "3                           what kind of concert ?     \n",
       "4  oh , i am sorry to hear that . i am sorry to h...   \n",
       "\n",
       "                                               empDG  \\\n",
       "0  oh no ! i am so sorry . i am so sorry . i am s...   \n",
       "1  i am so sorry to hear that . i can not like th...   \n",
       "2                        oh no ! that is a shame !     \n",
       "3                                what band is it ?     \n",
       "4  oh no ! i am so sorry . i am so sorry to hear ...   \n",
       "\n",
       "                                           utterance  \\\n",
       "0  [yeah about 10 years ago i had a horrifying ex...   \n",
       "1  [well , can you tell me about your experience ...   \n",
       "2  [i there , dont know what to do , jst broke up...   \n",
       "3  [i could not wait to go to the concert . , whi...   \n",
       "4  [i am so sad because i have read an article ab...   \n",
       "\n",
       "                         chatgpt_response_no_emotion  \\\n",
       "0  Wow, that sounds really scary! Have you been a...   \n",
       "1  As an AI language model, I don't really have \"...   \n",
       "2  Take some time to process your emotions, refle...   \n",
       "3  That's so exciting! Who is performing at the c...   \n",
       "4  I understand why that would make you feel sad,...   \n",
       "\n",
       "                          chatgpt_emotional_response  \\\n",
       "0  (fear, 99.56, I'm sorry to hear about your sca...   \n",
       "1  (curiosity, 99.7, As an AI language model, I d...   \n",
       "2  (confusion, 95.6, It's okay to feel lost and h...   \n",
       "3  (excitement, 99.32, Awesome, I hope you have a...   \n",
       "4  (sadness, 99.03, I'm sorry to hear that. It's ...   \n",
       "\n",
       "                            chatgpt_prompt2_response  \n",
       "0  That sounds really scary and traumatic, and it...  \n",
       "1  I'm sorry, as an AI language model, I don't ha...  \n",
       "2  I'm sorry to hear that, it's completely normal...  \n",
       "3  I can imagine how excited you must be! Going t...  \n",
       "4   I'm sorry to hear that. It's a tragic situation.  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_pickle(\"ChatEPT/first_10_percent_grouped_by_df\")\n",
    "#df[\"ed_target\"] = df.utterance.apply(lambda x: x[-1])\n",
    "#df.head()\n",
    "\n",
    "EmpDG_results_df = pd.read_pickle(\"EmpDG_results_df\")\n",
    "EmpDG_results_df = EmpDG_results_df.drop('utterance_2_emotion', axis=1)\n",
    "\n",
    "#results_df[\"ed_target\"] = results_df.utterance.apply(lambda x: x[-1])\n",
    "EmpDG_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f8547-508f-4d51-97e9-e394901fc0b4",
   "metadata": {},
   "source": [
    "# Labelling with Electra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368955cc-0894-4151-a244-50d06dfb3f74",
   "metadata": {},
   "source": [
    "## ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0393a5d1-c2b9-4a42-aff7-ea77318fd842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fbd8b2dd3546769788fca2698da209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"ref_emotion\"] = EmpDG_results_df[\"ref\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff5a33-92f8-458f-881b-561a28804ba5",
   "metadata": {},
   "source": [
    "## transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fc3c188f-33bf-4922-b5ca-dcb452421af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d68996f8043eab6e9154450ff3e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"transformer_emotion\"] = EmpDG_results_df[\"transformer\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377573a2-d761-4c9f-8910-877b4e8386cf",
   "metadata": {},
   "source": [
    "## emoprepend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "68cf9f0e-8eb4-48e8-a8a3-d95a5b27eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ede95bff16f4b0f8ec0864d8efd6598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"emoprepend_emotion\"] = EmpDG_results_df[\"emoprepend\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143eb495-d86d-48d7-a71e-69d4f2f5bac2",
   "metadata": {},
   "source": [
    "## moel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "63b16214-8e07-448c-ad34-f268e76b3b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729c202f019b40c49f0c6b50ca18b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"moel_emotion\"] = EmpDG_results_df[\"moel\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad7c52-4794-42e6-8fe6-011255e58313",
   "metadata": {},
   "source": [
    "## empDG_woD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "768dd897-1800-4dbc-bda3-7a50cce47a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3aadcbace3439f8f44a8772b4f5ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"empDG_woD_emotion\"] = EmpDG_results_df[\"empDG_woD\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85c447-836a-4df2-83ba-76267f802d59",
   "metadata": {},
   "source": [
    "## empDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "63567ced-62d3-4cc0-acd3-d6cc81fe223d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a168e646074fe897729405959d56b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"empDG_emotion\"] = EmpDG_results_df[\"empDG\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f727c-5306-45da-96ec-c0465c7dbba7",
   "metadata": {},
   "source": [
    "## chatgpt_response_no_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4cb87a29-f1dd-45bc-9cd5-9516f01e36e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628e17c3c7843418c390c2923d0e9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"chatgpt_response_no_emotion_emotion\"] = EmpDG_results_df[\"chatgpt_response_no_emotion\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8606096-086b-45df-9f9f-4dd6369471ea",
   "metadata": {},
   "source": [
    "## chatgpt_emotional_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "abf970ac-383d-4fa1-8366-e9aa9e763e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3c98f23cd84ff5960cc116316c6410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"chatgpt_emotional_response_emotion\"] = EmpDG_results_df[\"chatgpt_emotional_response\"].progress_apply(lambda x: predict_emotion_and_probability(x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc15504-c7ef-4861-b1fa-616a099b1238",
   "metadata": {},
   "source": [
    "## chatgpt_prompt2_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "66896737-5a18-426b-8fce-f4e8ffbe9527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb1e6f7b24a4d18adaaddaee9d480e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EmpDG_results_df[\"chatgpt_prompt2_response_emotion\"] = EmpDG_results_df[\"chatgpt_prompt2_response\"].progress_apply(lambda x: predict_emotion_and_probability(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9e1007e5-e8d7-428e-bd2d-5ebbdc4a473a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer</th>\n",
       "      <th>ref</th>\n",
       "      <th>emoprepend</th>\n",
       "      <th>moel</th>\n",
       "      <th>empDG_woD</th>\n",
       "      <th>empDG</th>\n",
       "      <th>utterance</th>\n",
       "      <th>chatgpt_response_no_emotion</th>\n",
       "      <th>chatgpt_emotional_response</th>\n",
       "      <th>chatgpt_prompt2_response</th>\n",
       "      <th>ref_emotion</th>\n",
       "      <th>transformer_emotion</th>\n",
       "      <th>emoprepend_emotion</th>\n",
       "      <th>moel_emotion</th>\n",
       "      <th>empDG_woD_emotion</th>\n",
       "      <th>empDG_emotion</th>\n",
       "      <th>chatgpt_response_no_emotion_emotion</th>\n",
       "      <th>chatgpt_emotional_response_emotion</th>\n",
       "      <th>chatgpt_prompt2_response_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh no , i am so sorry to hear that .</td>\n",
       "      <td>did you suffer any injuries ?</td>\n",
       "      <td>oh no , did they catch them ?</td>\n",
       "      <td>oh no ! i hate spiders !</td>\n",
       "      <td>oh man , that is terrible . i hope you are oka...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry . i am s...</td>\n",
       "      <td>[yeah about 10 years ago i had a horrifying ex...</td>\n",
       "      <td>Wow, that sounds really scary! Have you been a...</td>\n",
       "      <td>(fear, 99.56, I'm sorry to hear about your sca...</td>\n",
       "      <td>That sounds really scary and traumatic, and it...</td>\n",
       "      <td>(curiosity, 95.93)</td>\n",
       "      <td>(remorse, 74.2)</td>\n",
       "      <td>(confusion, 63.14)</td>\n",
       "      <td>(disapproval, 59.94)</td>\n",
       "      <td>(fear, 99.3)</td>\n",
       "      <td>(remorse, 92.65)</td>\n",
       "      <td>(fear, 99.77)</td>\n",
       "      <td>(caring, 31.36)</td>\n",
       "      <td>(fear, 99.37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that is really nice of them .</td>\n",
       "      <td>yeah i wanted to tell you about the time i was...</td>\n",
       "      <td>i am glad you are not good .</td>\n",
       "      <td>that is good , i am sure you are looking for t...</td>\n",
       "      <td>oh , i am sorry to hear that . i hope you are ...</td>\n",
       "      <td>i am so sorry to hear that . i can not like th...</td>\n",
       "      <td>[well , can you tell me about your experience ...</td>\n",
       "      <td>As an AI language model, I don't really have \"...</td>\n",
       "      <td>(curiosity, 99.7, As an AI language model, I d...</td>\n",
       "      <td>I'm sorry, as an AI language model, I don't ha...</td>\n",
       "      <td>(joy, 98.2)</td>\n",
       "      <td>(admiration, 99.15)</td>\n",
       "      <td>(disapproval, 53.55)</td>\n",
       "      <td>(admiration, 84.78)</td>\n",
       "      <td>(remorse, 88.28)</td>\n",
       "      <td>(remorse, 77.79)</td>\n",
       "      <td>(gratitude, 48.74)</td>\n",
       "      <td>(neutral, 99.91)</td>\n",
       "      <td>(remorse, 55.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is a shame . i am glad you got a lot of s...</td>\n",
       "      <td>sorry to hear ! do you have any idea about the...</td>\n",
       "      <td>that is a lot of thing to do that .</td>\n",
       "      <td>that is a good attitude to do .</td>\n",
       "      <td>that is a bummer . i have a lot of people .</td>\n",
       "      <td>oh no ! that is a shame !</td>\n",
       "      <td>[i there , dont know what to do , jst broke up...</td>\n",
       "      <td>Take some time to process your emotions, refle...</td>\n",
       "      <td>(confusion, 95.6, It's okay to feel lost and h...</td>\n",
       "      <td>I'm sorry to hear that, it's completely normal...</td>\n",
       "      <td>(remorse, 81.61)</td>\n",
       "      <td>(embarrassment, 73.09)</td>\n",
       "      <td>(neutral, 99.85)</td>\n",
       "      <td>(admiration, 99.69)</td>\n",
       "      <td>(disappointment, 39.66)</td>\n",
       "      <td>(embarrassment, 99.21)</td>\n",
       "      <td>(caring, 99.56)</td>\n",
       "      <td>(caring, 99.23)</td>\n",
       "      <td>(caring, 55.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what concert ?</td>\n",
       "      <td>which concert ?</td>\n",
       "      <td>that is awesome ! what band is it ?</td>\n",
       "      <td>that is awesome ! what is it ?</td>\n",
       "      <td>what kind of concert ?</td>\n",
       "      <td>what band is it ?</td>\n",
       "      <td>[i could not wait to go to the concert . , whi...</td>\n",
       "      <td>That's so exciting! Who is performing at the c...</td>\n",
       "      <td>(excitement, 99.32, Awesome, I hope you have a...</td>\n",
       "      <td>I can imagine how excited you must be! Going t...</td>\n",
       "      <td>(neutral, 92.97)</td>\n",
       "      <td>(neutral, 95.96)</td>\n",
       "      <td>(admiration, 91.49)</td>\n",
       "      <td>(excitement, 80.11)</td>\n",
       "      <td>(curiosity, 58.39)</td>\n",
       "      <td>(neutral, 49.75)</td>\n",
       "      <td>(excitement, 79.53)</td>\n",
       "      <td>(admiration, 46.89)</td>\n",
       "      <td>(excitement, 78.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am sorry to hear that . i am sure you will b...</td>\n",
       "      <td>ugh , those articles always get me too ... : (...</td>\n",
       "      <td>i am sorry to hear that . i am glad you are no...</td>\n",
       "      <td>i am sorry to hear that . i know how you feel .</td>\n",
       "      <td>oh , i am sorry to hear that . i am sorry to h...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry to hear ...</td>\n",
       "      <td>[i am so sad because i have read an article ab...</td>\n",
       "      <td>I understand why that would make you feel sad,...</td>\n",
       "      <td>(sadness, 99.03, I'm sorry to hear that. It's ...</td>\n",
       "      <td>I'm sorry to hear that. It's a tragic situation.</td>\n",
       "      <td>(annoyance, 58.27)</td>\n",
       "      <td>(remorse, 84.84)</td>\n",
       "      <td>(remorse, 83.37)</td>\n",
       "      <td>(remorse, 67.44)</td>\n",
       "      <td>(remorse, 87.63)</td>\n",
       "      <td>(remorse, 94.31)</td>\n",
       "      <td>(sadness, 99.24)</td>\n",
       "      <td>(caring, 85.01)</td>\n",
       "      <td>(remorse, 66.34)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transformer  \\\n",
       "0             oh no , i am so sorry to hear that .     \n",
       "1                    that is really nice of them .     \n",
       "2  that is a shame . i am glad you got a lot of s...   \n",
       "3                                   what concert ?     \n",
       "4  i am sorry to hear that . i am sure you will b...   \n",
       "\n",
       "                                                 ref  \\\n",
       "0                     did you suffer any injuries ?    \n",
       "1  yeah i wanted to tell you about the time i was...   \n",
       "2  sorry to hear ! do you have any idea about the...   \n",
       "3                                   which concert ?    \n",
       "4  ugh , those articles always get me too ... : (...   \n",
       "\n",
       "                                          emoprepend  \\\n",
       "0                    oh no , did they catch them ?     \n",
       "1                     i am glad you are not good .     \n",
       "2              that is a lot of thing to do that .     \n",
       "3              that is awesome ! what band is it ?     \n",
       "4  i am sorry to hear that . i am glad you are no...   \n",
       "\n",
       "                                                moel  \\\n",
       "0                         oh no ! i hate spiders !     \n",
       "1  that is good , i am sure you are looking for t...   \n",
       "2                  that is a good attitude to do .     \n",
       "3                   that is awesome ! what is it ?     \n",
       "4  i am sorry to hear that . i know how you feel .     \n",
       "\n",
       "                                           empDG_woD  \\\n",
       "0  oh man , that is terrible . i hope you are oka...   \n",
       "1  oh , i am sorry to hear that . i hope you are ...   \n",
       "2      that is a bummer . i have a lot of people .     \n",
       "3                           what kind of concert ?     \n",
       "4  oh , i am sorry to hear that . i am sorry to h...   \n",
       "\n",
       "                                               empDG  \\\n",
       "0  oh no ! i am so sorry . i am so sorry . i am s...   \n",
       "1  i am so sorry to hear that . i can not like th...   \n",
       "2                        oh no ! that is a shame !     \n",
       "3                                what band is it ?     \n",
       "4  oh no ! i am so sorry . i am so sorry to hear ...   \n",
       "\n",
       "                                           utterance  \\\n",
       "0  [yeah about 10 years ago i had a horrifying ex...   \n",
       "1  [well , can you tell me about your experience ...   \n",
       "2  [i there , dont know what to do , jst broke up...   \n",
       "3  [i could not wait to go to the concert . , whi...   \n",
       "4  [i am so sad because i have read an article ab...   \n",
       "\n",
       "                         chatgpt_response_no_emotion  \\\n",
       "0  Wow, that sounds really scary! Have you been a...   \n",
       "1  As an AI language model, I don't really have \"...   \n",
       "2  Take some time to process your emotions, refle...   \n",
       "3  That's so exciting! Who is performing at the c...   \n",
       "4  I understand why that would make you feel sad,...   \n",
       "\n",
       "                          chatgpt_emotional_response  \\\n",
       "0  (fear, 99.56, I'm sorry to hear about your sca...   \n",
       "1  (curiosity, 99.7, As an AI language model, I d...   \n",
       "2  (confusion, 95.6, It's okay to feel lost and h...   \n",
       "3  (excitement, 99.32, Awesome, I hope you have a...   \n",
       "4  (sadness, 99.03, I'm sorry to hear that. It's ...   \n",
       "\n",
       "                            chatgpt_prompt2_response         ref_emotion  \\\n",
       "0  That sounds really scary and traumatic, and it...  (curiosity, 95.93)   \n",
       "1  I'm sorry, as an AI language model, I don't ha...         (joy, 98.2)   \n",
       "2  I'm sorry to hear that, it's completely normal...    (remorse, 81.61)   \n",
       "3  I can imagine how excited you must be! Going t...    (neutral, 92.97)   \n",
       "4   I'm sorry to hear that. It's a tragic situation.  (annoyance, 58.27)   \n",
       "\n",
       "      transformer_emotion    emoprepend_emotion          moel_emotion  \\\n",
       "0         (remorse, 74.2)    (confusion, 63.14)  (disapproval, 59.94)   \n",
       "1     (admiration, 99.15)  (disapproval, 53.55)   (admiration, 84.78)   \n",
       "2  (embarrassment, 73.09)      (neutral, 99.85)   (admiration, 99.69)   \n",
       "3        (neutral, 95.96)   (admiration, 91.49)   (excitement, 80.11)   \n",
       "4        (remorse, 84.84)      (remorse, 83.37)      (remorse, 67.44)   \n",
       "\n",
       "         empDG_woD_emotion           empDG_emotion  \\\n",
       "0             (fear, 99.3)        (remorse, 92.65)   \n",
       "1         (remorse, 88.28)        (remorse, 77.79)   \n",
       "2  (disappointment, 39.66)  (embarrassment, 99.21)   \n",
       "3       (curiosity, 58.39)        (neutral, 49.75)   \n",
       "4         (remorse, 87.63)        (remorse, 94.31)   \n",
       "\n",
       "  chatgpt_response_no_emotion_emotion chatgpt_emotional_response_emotion  \\\n",
       "0                       (fear, 99.77)                    (caring, 31.36)   \n",
       "1                  (gratitude, 48.74)                   (neutral, 99.91)   \n",
       "2                     (caring, 99.56)                    (caring, 99.23)   \n",
       "3                 (excitement, 79.53)                (admiration, 46.89)   \n",
       "4                    (sadness, 99.24)                    (caring, 85.01)   \n",
       "\n",
       "  chatgpt_prompt2_response_emotion  \n",
       "0                    (fear, 99.37)  \n",
       "1                 (remorse, 55.92)  \n",
       "2                  (caring, 55.73)  \n",
       "3              (excitement, 78.14)  \n",
       "4                 (remorse, 66.34)  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6f27e10e-d436-4c7d-9d8b-496cdc399323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EmpDG_results_df.to_pickle(\"EmpDG_results_df_labelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bf2bc-3a07-496e-a2ec-601b7cc6e4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c635d298-4885-479d-beab-d985fdcca000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c5440-c296-43d4-8589-8ef557b32ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9a8fe0b-6481-41a9-b403-23f7c7301022",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmpDG_results_df = pd.read_pickle(\"EmpDG_results_df_labelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70709aa0-e8b1-4cfa-85b3-d650690729cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2713"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EmpDG_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd9f0d6e-0f65-436b-8a8c-1b4826229e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.ref_emotion.apply(lambda x: x[0]) != EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: x[0])]\n",
    "#EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.ref_emotion.apply(lambda x: x[0]) != \"neutral\"]\n",
    "\n",
    "#EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: x[0]) != \"caring\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d59089-f168-4462-a42d-9e573e599eef",
   "metadata": {},
   "source": [
    "when is ChatEPT bad: \n",
    "\n",
    "- When the user is neutral \n",
    "- When ref is a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "79e4ec8f-d74d-4645-a2a3-60307ff8fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: x[0]) == \"caring\"\n",
    "EmpDG_results_df.ref_emotion.loc[mask] = EmpDG_results_df.chatgpt_emotional_response_emotion.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7d207b5-9cdd-4fbc-a679-d117d53a3b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer</th>\n",
       "      <th>ref</th>\n",
       "      <th>emoprepend</th>\n",
       "      <th>moel</th>\n",
       "      <th>empDG_woD</th>\n",
       "      <th>empDG</th>\n",
       "      <th>utterance</th>\n",
       "      <th>chatgpt_response_no_emotion</th>\n",
       "      <th>chatgpt_emotional_response</th>\n",
       "      <th>chatgpt_prompt2_response</th>\n",
       "      <th>ref_emotion</th>\n",
       "      <th>transformer_emotion</th>\n",
       "      <th>emoprepend_emotion</th>\n",
       "      <th>moel_emotion</th>\n",
       "      <th>empDG_woD_emotion</th>\n",
       "      <th>empDG_emotion</th>\n",
       "      <th>chatgpt_response_no_emotion_emotion</th>\n",
       "      <th>chatgpt_emotional_response_emotion</th>\n",
       "      <th>chatgpt_prompt2_response_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh no , i am so sorry to hear that .</td>\n",
       "      <td>did you suffer any injuries ?</td>\n",
       "      <td>oh no , did they catch them ?</td>\n",
       "      <td>oh no ! i hate spiders !</td>\n",
       "      <td>oh man , that is terrible . i hope you are oka...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry . i am s...</td>\n",
       "      <td>[yeah about 10 years ago i had a horrifying ex...</td>\n",
       "      <td>Wow, that sounds really scary! Have you been a...</td>\n",
       "      <td>(fear, 99.56, I'm sorry to hear about your sca...</td>\n",
       "      <td>That sounds really scary and traumatic, and it...</td>\n",
       "      <td>(caring, 31.36)</td>\n",
       "      <td>(remorse, 74.2)</td>\n",
       "      <td>(confusion, 63.14)</td>\n",
       "      <td>(disapproval, 59.94)</td>\n",
       "      <td>(fear, 99.3)</td>\n",
       "      <td>(remorse, 92.65)</td>\n",
       "      <td>(fear, 99.77)</td>\n",
       "      <td>(caring, 31.36)</td>\n",
       "      <td>(fear, 99.37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is a shame . i am glad you got a lot of s...</td>\n",
       "      <td>sorry to hear ! do you have any idea about the...</td>\n",
       "      <td>that is a lot of thing to do that .</td>\n",
       "      <td>that is a good attitude to do .</td>\n",
       "      <td>that is a bummer . i have a lot of people .</td>\n",
       "      <td>oh no ! that is a shame !</td>\n",
       "      <td>[i there , dont know what to do , jst broke up...</td>\n",
       "      <td>Take some time to process your emotions, refle...</td>\n",
       "      <td>(confusion, 95.6, It's okay to feel lost and h...</td>\n",
       "      <td>I'm sorry to hear that, it's completely normal...</td>\n",
       "      <td>(caring, 99.23)</td>\n",
       "      <td>(embarrassment, 73.09)</td>\n",
       "      <td>(neutral, 99.85)</td>\n",
       "      <td>(admiration, 99.69)</td>\n",
       "      <td>(disappointment, 39.66)</td>\n",
       "      <td>(embarrassment, 99.21)</td>\n",
       "      <td>(caring, 99.56)</td>\n",
       "      <td>(caring, 99.23)</td>\n",
       "      <td>(caring, 55.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am sorry to hear that . i am sure you will b...</td>\n",
       "      <td>ugh , those articles always get me too ... : (...</td>\n",
       "      <td>i am sorry to hear that . i am glad you are no...</td>\n",
       "      <td>i am sorry to hear that . i know how you feel .</td>\n",
       "      <td>oh , i am sorry to hear that . i am sorry to h...</td>\n",
       "      <td>oh no ! i am so sorry . i am so sorry to hear ...</td>\n",
       "      <td>[i am so sad because i have read an article ab...</td>\n",
       "      <td>I understand why that would make you feel sad,...</td>\n",
       "      <td>(sadness, 99.03, I'm sorry to hear that. It's ...</td>\n",
       "      <td>I'm sorry to hear that. It's a tragic situation.</td>\n",
       "      <td>(caring, 85.01)</td>\n",
       "      <td>(remorse, 84.84)</td>\n",
       "      <td>(remorse, 83.37)</td>\n",
       "      <td>(remorse, 67.44)</td>\n",
       "      <td>(remorse, 87.63)</td>\n",
       "      <td>(remorse, 94.31)</td>\n",
       "      <td>(sadness, 99.24)</td>\n",
       "      <td>(caring, 85.01)</td>\n",
       "      <td>(remorse, 66.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that is so sweet . i am sorry to hear that .</td>\n",
       "      <td>that is nice of you . what did you do ?</td>\n",
       "      <td>that is so nice of him ! i hope he was not hur...</td>\n",
       "      <td>oh no , i bet he was a good kid</td>\n",
       "      <td>oh , that is so cool ! what did he do ?</td>\n",
       "      <td>oh wow ! how did it go ?</td>\n",
       "      <td>[[\"so my friend 's baby fell down and scraped ...</td>\n",
       "      <td>\"Oh no! Poor little guy. Did you give him a ba...</td>\n",
       "      <td>(sadness, 95.47, Oh no! That must have hurt a ...</td>\n",
       "      <td>I can imagine how upset you must have been see...</td>\n",
       "      <td>(caring, 98.14)</td>\n",
       "      <td>(admiration, 96.72)</td>\n",
       "      <td>(admiration, 96.3)</td>\n",
       "      <td>(admiration, 59.06)</td>\n",
       "      <td>(admiration, 51.53)</td>\n",
       "      <td>(excitement, 88.64)</td>\n",
       "      <td>(disappointment, 65.1)</td>\n",
       "      <td>(caring, 98.14)</td>\n",
       "      <td>(admiration, 81.96)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that is great ! i am sure he will be fine .</td>\n",
       "      <td>he will , i have faith .</td>\n",
       "      <td>i am sorry to hear that . i hope he gets it .</td>\n",
       "      <td>that is a good news . i hope you get it for hi...</td>\n",
       "      <td>i am sorry to hear that . i hope he gets bette...</td>\n",
       "      <td>i am sorry to hear that . i hope you have a go...</td>\n",
       "      <td>[my husband lost a job but i am hoping he can ...</td>\n",
       "      <td>I'm sorry to hear that your husband lost his j...</td>\n",
       "      <td>(optimism, 98.81, I'm sorry to hear about the ...</td>\n",
       "      <td>I am sorry to hear that your husband is going ...</td>\n",
       "      <td>(caring, 98.57)</td>\n",
       "      <td>(admiration, 93.13)</td>\n",
       "      <td>(remorse, 72.18)</td>\n",
       "      <td>(optimism, 49.54)</td>\n",
       "      <td>(remorse, 64.86)</td>\n",
       "      <td>(remorse, 75.93)</td>\n",
       "      <td>(optimism, 83.93)</td>\n",
       "      <td>(caring, 98.57)</td>\n",
       "      <td>(caring, 41.65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>oh no , that is horrible . i hope you were not...</td>\n",
       "      <td>sheesh that is brutal , did you smack him ?</td>\n",
       "      <td>that is terrible . i am sorry to hear that .</td>\n",
       "      <td>that is so sad . i am sorry you had that to ha...</td>\n",
       "      <td>that is a good thing . i am sorry to hear that...</td>\n",
       "      <td>that is a shame .</td>\n",
       "      <td>[my friend slept with a girl i like . i feel h...</td>\n",
       "      <td>It's understandable to feel upset and hurt. Ta...</td>\n",
       "      <td>(annoyance, 52.25, It's important to communica...</td>\n",
       "      <td>I'm sorry that happened. It's okay to take som...</td>\n",
       "      <td>(caring, 59.28)</td>\n",
       "      <td>(fear, 99.51)</td>\n",
       "      <td>(fear, 57.46)</td>\n",
       "      <td>(sadness, 97.71)</td>\n",
       "      <td>(remorse, 44.89)</td>\n",
       "      <td>(embarrassment, 58.28)</td>\n",
       "      <td>(caring, 99.5)</td>\n",
       "      <td>(caring, 59.28)</td>\n",
       "      <td>(caring, 65.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>i am sorry to hear that .</td>\n",
       "      <td>always try to brush your teeth at least twice ...</td>\n",
       "      <td>i am sorry to hear that .</td>\n",
       "      <td>i agree , kids can be so inconsiderate .</td>\n",
       "      <td>i agree , it is a lot of people .</td>\n",
       "      <td>i agree . i agree with you .</td>\n",
       "      <td>[teeth are weird , but also take a lot of upke...</td>\n",
       "      <td>I know what you mean! Flossing and brushing ca...</td>\n",
       "      <td>(annoyance, 98.32, I understand that it can be...</td>\n",
       "      <td>I hear you, dental hygiene can be a hassle. Bu...</td>\n",
       "      <td>(caring, 99.01)</td>\n",
       "      <td>(remorse, 73.19)</td>\n",
       "      <td>(remorse, 73.19)</td>\n",
       "      <td>(approval, 99.68)</td>\n",
       "      <td>(approval, 99.85)</td>\n",
       "      <td>(approval, 99.76)</td>\n",
       "      <td>(approval, 98.04)</td>\n",
       "      <td>(caring, 99.01)</td>\n",
       "      <td>(caring, 95.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>oh no , i am sorry to hear that .</td>\n",
       "      <td>yea , its a good idea to take time for yoursel...</td>\n",
       "      <td>i am sorry to hear that . i hope you are not g...</td>\n",
       "      <td>i am sorry to hear that . what is wrong ?</td>\n",
       "      <td>i am sorry to hear that . i hope you are okay .</td>\n",
       "      <td>i am so sorry to hear that . i am so sorry to ...</td>\n",
       "      <td>[when i can not take a breather in the day i f...</td>\n",
       "      <td>That sounds really overwhelming. Do you need s...</td>\n",
       "      <td>(annoyance, 43.54, It's important to make time...</td>\n",
       "      <td>I'm sorry you feel that way. It must be tough ...</td>\n",
       "      <td>(caring, 43.5)</td>\n",
       "      <td>(remorse, 63.33)</td>\n",
       "      <td>(remorse, 83.6)</td>\n",
       "      <td>(remorse, 84.77)</td>\n",
       "      <td>(remorse, 88.63)</td>\n",
       "      <td>(remorse, 94.56)</td>\n",
       "      <td>(curiosity, 96.98)</td>\n",
       "      <td>(caring, 43.5)</td>\n",
       "      <td>(remorse, 92.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>i am sorry to hear that . what did you do ?</td>\n",
       "      <td>yeah as a child it is hard to see other kids w...</td>\n",
       "      <td>i am sorry to hear that . i am sure they were ...</td>\n",
       "      <td>i know what you mean ... i mean i wish i was m...</td>\n",
       "      <td>i love the new school year . i was a lot of my...</td>\n",
       "      <td>i can relate . i was also looking for a new sc...</td>\n",
       "      <td>[when i was in elementary school i was envious...</td>\n",
       "      <td>It's natural to want to fit in during school. ...</td>\n",
       "      <td>(pride, 37.81, It's natural to feel envious so...</td>\n",
       "      <td>I understand. It's natural to desire acceptanc...</td>\n",
       "      <td>(caring, 75.49)</td>\n",
       "      <td>(remorse, 86.59)</td>\n",
       "      <td>(remorse, 86.9)</td>\n",
       "      <td>(disapproval, 97.47)</td>\n",
       "      <td>(love, 88.8)</td>\n",
       "      <td>(annoyance, 53.19)</td>\n",
       "      <td>(approval, 83.71)</td>\n",
       "      <td>(caring, 75.49)</td>\n",
       "      <td>(approval, 99.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>oh no , that is terrible . i hope it is not a ...</td>\n",
       "      <td>oh wow that is weird . did you say anything to...</td>\n",
       "      <td>oh no , did you get out of it ?</td>\n",
       "      <td>that is not good . i would have been so scared...</td>\n",
       "      <td>that is terrible . did you call the police ?</td>\n",
       "      <td>that is terrible . what did you do ?</td>\n",
       "      <td>[some random dude walked into my room while i ...</td>\n",
       "      <td>That sounds really strange and unsettling, are...</td>\n",
       "      <td>(embarrassment, 93.91, That definitely sounds ...</td>\n",
       "      <td>That sounds really uncomfortable and unexpecte...</td>\n",
       "      <td>(caring, 97.97)</td>\n",
       "      <td>(fear, 98.94)</td>\n",
       "      <td>(curiosity, 54.5)</td>\n",
       "      <td>(fear, 96.57)</td>\n",
       "      <td>(curiosity, 92.19)</td>\n",
       "      <td>(fear, 99.57)</td>\n",
       "      <td>(caring, 58.26)</td>\n",
       "      <td>(caring, 97.97)</td>\n",
       "      <td>(confusion, 43.45)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transformer  \\\n",
       "0                oh no , i am so sorry to hear that .     \n",
       "2     that is a shame . i am glad you got a lot of s...   \n",
       "4     i am sorry to hear that . i am sure you will b...   \n",
       "5        that is so sweet . i am sorry to hear that .     \n",
       "6         that is great ! i am sure he will be fine .     \n",
       "...                                                 ...   \n",
       "2670  oh no , that is horrible . i hope you were not...   \n",
       "2672                        i am sorry to hear that .     \n",
       "2687                oh no , i am sorry to hear that .     \n",
       "2688      i am sorry to hear that . what did you do ?     \n",
       "2706  oh no , that is terrible . i hope it is not a ...   \n",
       "\n",
       "                                                    ref  \\\n",
       "0                        did you suffer any injuries ?    \n",
       "2     sorry to hear ! do you have any idea about the...   \n",
       "4     ugh , those articles always get me too ... : (...   \n",
       "5              that is nice of you . what did you do ?    \n",
       "6                             he will , i have faith .    \n",
       "...                                                 ...   \n",
       "2670       sheesh that is brutal , did you smack him ?    \n",
       "2672  always try to brush your teeth at least twice ...   \n",
       "2687  yea , its a good idea to take time for yoursel...   \n",
       "2688  yeah as a child it is hard to see other kids w...   \n",
       "2706  oh wow that is weird . did you say anything to...   \n",
       "\n",
       "                                             emoprepend  \\\n",
       "0                       oh no , did they catch them ?     \n",
       "2                 that is a lot of thing to do that .     \n",
       "4     i am sorry to hear that . i am glad you are no...   \n",
       "5     that is so nice of him ! i hope he was not hur...   \n",
       "6       i am sorry to hear that . i hope he gets it .     \n",
       "...                                                 ...   \n",
       "2670     that is terrible . i am sorry to hear that .     \n",
       "2672                        i am sorry to hear that .     \n",
       "2687  i am sorry to hear that . i hope you are not g...   \n",
       "2688  i am sorry to hear that . i am sure they were ...   \n",
       "2706                  oh no , did you get out of it ?     \n",
       "\n",
       "                                                   moel  \\\n",
       "0                            oh no ! i hate spiders !     \n",
       "2                     that is a good attitude to do .     \n",
       "4     i am sorry to hear that . i know how you feel .     \n",
       "5                     oh no , i bet he was a good kid     \n",
       "6     that is a good news . i hope you get it for hi...   \n",
       "...                                                 ...   \n",
       "2670  that is so sad . i am sorry you had that to ha...   \n",
       "2672         i agree , kids can be so inconsiderate .     \n",
       "2687        i am sorry to hear that . what is wrong ?     \n",
       "2688  i know what you mean ... i mean i wish i was m...   \n",
       "2706  that is not good . i would have been so scared...   \n",
       "\n",
       "                                              empDG_woD  \\\n",
       "0     oh man , that is terrible . i hope you are oka...   \n",
       "2         that is a bummer . i have a lot of people .     \n",
       "4     oh , i am sorry to hear that . i am sorry to h...   \n",
       "5             oh , that is so cool ! what did he do ?     \n",
       "6     i am sorry to hear that . i hope he gets bette...   \n",
       "...                                                 ...   \n",
       "2670  that is a good thing . i am sorry to hear that...   \n",
       "2672                i agree , it is a lot of people .     \n",
       "2687  i am sorry to hear that . i hope you are okay .     \n",
       "2688  i love the new school year . i was a lot of my...   \n",
       "2706     that is terrible . did you call the police ?     \n",
       "\n",
       "                                                  empDG  \\\n",
       "0     oh no ! i am so sorry . i am so sorry . i am s...   \n",
       "2                           oh no ! that is a shame !     \n",
       "4     oh no ! i am so sorry . i am so sorry to hear ...   \n",
       "5                            oh wow ! how did it go ?     \n",
       "6     i am sorry to hear that . i hope you have a go...   \n",
       "...                                                 ...   \n",
       "2670                                that is a shame .     \n",
       "2672                     i agree . i agree with you .     \n",
       "2687  i am so sorry to hear that . i am so sorry to ...   \n",
       "2688  i can relate . i was also looking for a new sc...   \n",
       "2706             that is terrible . what did you do ?     \n",
       "\n",
       "                                              utterance  \\\n",
       "0     [yeah about 10 years ago i had a horrifying ex...   \n",
       "2     [i there , dont know what to do , jst broke up...   \n",
       "4     [i am so sad because i have read an article ab...   \n",
       "5     [[\"so my friend 's baby fell down and scraped ...   \n",
       "6     [my husband lost a job but i am hoping he can ...   \n",
       "...                                                 ...   \n",
       "2670  [my friend slept with a girl i like . i feel h...   \n",
       "2672  [teeth are weird , but also take a lot of upke...   \n",
       "2687  [when i can not take a breather in the day i f...   \n",
       "2688  [when i was in elementary school i was envious...   \n",
       "2706  [some random dude walked into my room while i ...   \n",
       "\n",
       "                            chatgpt_response_no_emotion  \\\n",
       "0     Wow, that sounds really scary! Have you been a...   \n",
       "2     Take some time to process your emotions, refle...   \n",
       "4     I understand why that would make you feel sad,...   \n",
       "5     \"Oh no! Poor little guy. Did you give him a ba...   \n",
       "6     I'm sorry to hear that your husband lost his j...   \n",
       "...                                                 ...   \n",
       "2670  It's understandable to feel upset and hurt. Ta...   \n",
       "2672  I know what you mean! Flossing and brushing ca...   \n",
       "2687  That sounds really overwhelming. Do you need s...   \n",
       "2688  It's natural to want to fit in during school. ...   \n",
       "2706  That sounds really strange and unsettling, are...   \n",
       "\n",
       "                             chatgpt_emotional_response  \\\n",
       "0     (fear, 99.56, I'm sorry to hear about your sca...   \n",
       "2     (confusion, 95.6, It's okay to feel lost and h...   \n",
       "4     (sadness, 99.03, I'm sorry to hear that. It's ...   \n",
       "5     (sadness, 95.47, Oh no! That must have hurt a ...   \n",
       "6     (optimism, 98.81, I'm sorry to hear about the ...   \n",
       "...                                                 ...   \n",
       "2670  (annoyance, 52.25, It's important to communica...   \n",
       "2672  (annoyance, 98.32, I understand that it can be...   \n",
       "2687  (annoyance, 43.54, It's important to make time...   \n",
       "2688  (pride, 37.81, It's natural to feel envious so...   \n",
       "2706  (embarrassment, 93.91, That definitely sounds ...   \n",
       "\n",
       "                               chatgpt_prompt2_response      ref_emotion  \\\n",
       "0     That sounds really scary and traumatic, and it...  (caring, 31.36)   \n",
       "2     I'm sorry to hear that, it's completely normal...  (caring, 99.23)   \n",
       "4      I'm sorry to hear that. It's a tragic situation.  (caring, 85.01)   \n",
       "5     I can imagine how upset you must have been see...  (caring, 98.14)   \n",
       "6     I am sorry to hear that your husband is going ...  (caring, 98.57)   \n",
       "...                                                 ...              ...   \n",
       "2670  I'm sorry that happened. It's okay to take som...  (caring, 59.28)   \n",
       "2672  I hear you, dental hygiene can be a hassle. Bu...  (caring, 99.01)   \n",
       "2687  I'm sorry you feel that way. It must be tough ...   (caring, 43.5)   \n",
       "2688  I understand. It's natural to desire acceptanc...  (caring, 75.49)   \n",
       "2706  That sounds really uncomfortable and unexpecte...  (caring, 97.97)   \n",
       "\n",
       "         transformer_emotion  emoprepend_emotion          moel_emotion  \\\n",
       "0            (remorse, 74.2)  (confusion, 63.14)  (disapproval, 59.94)   \n",
       "2     (embarrassment, 73.09)    (neutral, 99.85)   (admiration, 99.69)   \n",
       "4           (remorse, 84.84)    (remorse, 83.37)      (remorse, 67.44)   \n",
       "5        (admiration, 96.72)  (admiration, 96.3)   (admiration, 59.06)   \n",
       "6        (admiration, 93.13)    (remorse, 72.18)     (optimism, 49.54)   \n",
       "...                      ...                 ...                   ...   \n",
       "2670           (fear, 99.51)       (fear, 57.46)      (sadness, 97.71)   \n",
       "2672        (remorse, 73.19)    (remorse, 73.19)     (approval, 99.68)   \n",
       "2687        (remorse, 63.33)     (remorse, 83.6)      (remorse, 84.77)   \n",
       "2688        (remorse, 86.59)     (remorse, 86.9)  (disapproval, 97.47)   \n",
       "2706           (fear, 98.94)   (curiosity, 54.5)         (fear, 96.57)   \n",
       "\n",
       "            empDG_woD_emotion           empDG_emotion  \\\n",
       "0                (fear, 99.3)        (remorse, 92.65)   \n",
       "2     (disappointment, 39.66)  (embarrassment, 99.21)   \n",
       "4            (remorse, 87.63)        (remorse, 94.31)   \n",
       "5         (admiration, 51.53)     (excitement, 88.64)   \n",
       "6            (remorse, 64.86)        (remorse, 75.93)   \n",
       "...                       ...                     ...   \n",
       "2670         (remorse, 44.89)  (embarrassment, 58.28)   \n",
       "2672        (approval, 99.85)       (approval, 99.76)   \n",
       "2687         (remorse, 88.63)        (remorse, 94.56)   \n",
       "2688             (love, 88.8)      (annoyance, 53.19)   \n",
       "2706       (curiosity, 92.19)           (fear, 99.57)   \n",
       "\n",
       "     chatgpt_response_no_emotion_emotion chatgpt_emotional_response_emotion  \\\n",
       "0                          (fear, 99.77)                    (caring, 31.36)   \n",
       "2                        (caring, 99.56)                    (caring, 99.23)   \n",
       "4                       (sadness, 99.24)                    (caring, 85.01)   \n",
       "5                 (disappointment, 65.1)                    (caring, 98.14)   \n",
       "6                      (optimism, 83.93)                    (caring, 98.57)   \n",
       "...                                  ...                                ...   \n",
       "2670                      (caring, 99.5)                    (caring, 59.28)   \n",
       "2672                   (approval, 98.04)                    (caring, 99.01)   \n",
       "2687                  (curiosity, 96.98)                     (caring, 43.5)   \n",
       "2688                   (approval, 83.71)                    (caring, 75.49)   \n",
       "2706                     (caring, 58.26)                    (caring, 97.97)   \n",
       "\n",
       "     chatgpt_prompt2_response_emotion  \n",
       "0                       (fear, 99.37)  \n",
       "2                     (caring, 55.73)  \n",
       "4                    (remorse, 66.34)  \n",
       "5                 (admiration, 81.96)  \n",
       "6                     (caring, 41.65)  \n",
       "...                               ...  \n",
       "2670                  (caring, 65.11)  \n",
       "2672                  (caring, 95.15)  \n",
       "2687                 (remorse, 92.92)  \n",
       "2688                (approval, 99.78)  \n",
       "2706               (confusion, 43.45)  \n",
       "\n",
       "[568 rows x 19 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a07ab8ff-1150-4e2c-a699-2443891e708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: x[0]) != \"caring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4d4266f-229a-4064-b461-bf6d3d85fdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2713"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EmpDG_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3610aa0-8d62-49bc-968f-7a367f0405fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b08411f9-3efe-4d85-8a14-7a78f93f933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Context ##\n",
      "i was so ashamed when i threw up in public the other day \n",
      "## Reference ##\n",
      "oh.. were you sick ? \n",
      "## ChatGPT ##\n",
      "Don't be too hard on yourself, it happens to the best of us.\n",
      "## ChatEPT ##\n",
      "('embarrassment', 98.73, \"It's okay to feel embarrassed, but remember that it's a natural bodily function and happens to everyone at some point. Don't be too hard on yourself!\")\n",
      "\n",
      "## Reference emotion ##\n",
      "('confusion', 59.36)\n",
      "## ChatGPT emotion ##\n",
      "('caring', 99.56)\n",
      "## ChatEPT emotion ##\n",
      "('caring', 93.73)\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(EmpDG_results_df))\n",
    "row = EmpDG_results_df.iloc[i]\n",
    "print(\"## Context ##\")\n",
    "print(row.utterance[0])\n",
    "print(\"## Reference ##\")\n",
    "print(row.ref)\n",
    "print(\"## ChatGPT ##\")\n",
    "print(row.chatgpt_response_no_emotion)\n",
    "print(\"## ChatEPT ##\")\n",
    "print(row.chatgpt_emotional_response)\n",
    "print()\n",
    "print(\"## Reference emotion ##\")\n",
    "print(row.ref_emotion)\n",
    "print(\"## ChatGPT emotion ##\")\n",
    "print(row.chatgpt_response_no_emotion_emotion)\n",
    "print(\"## ChatEPT emotion ##\")\n",
    "print(row.chatgpt_emotional_response_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0a50204-2dbd-4230-a186-54aefac4b8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admiration        485\n",
       "caring            403\n",
       "curiosity         244\n",
       "approval          171\n",
       "joy               148\n",
       "excitement        111\n",
       "fear               84\n",
       "sadness            81\n",
       "love               60\n",
       "optimism           58\n",
       "remorse            56\n",
       "annoyance          43\n",
       "gratitude          37\n",
       "anger              37\n",
       "neutral            33\n",
       "disapproval        26\n",
       "embarrassment      19\n",
       "surprise           19\n",
       "disappointment     16\n",
       "disgust            13\n",
       "confusion          11\n",
       "amusement           7\n",
       "nervousness         5\n",
       "pride               3\n",
       "relief              2\n",
       "realization         2\n",
       "grief               2\n",
       "desire              1\n",
       "Name: chatgpt_response_no_emotion_emotion, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df.chatgpt_response_no_emotion_emotion.apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b39e0369-74dc-421e-941c-f592cbce24a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caring            537\n",
       "admiration        490\n",
       "joy               191\n",
       "approval          189\n",
       "curiosity         166\n",
       "remorse            84\n",
       "sadness            73\n",
       "optimism           68\n",
       "excitement         66\n",
       "love               56\n",
       "gratitude          48\n",
       "neutral            34\n",
       "annoyance          33\n",
       "fear               25\n",
       "anger              23\n",
       "disapproval        23\n",
       "disappointment     15\n",
       "embarrassment      14\n",
       "nervousness         8\n",
       "confusion           8\n",
       "surprise            8\n",
       "disgust             5\n",
       "amusement           4\n",
       "realization         3\n",
       "relief              2\n",
       "desire              2\n",
       "pride               1\n",
       "grief               1\n",
       "Name: chatgpt_emotional_response_emotion, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "707a4c45-1366-4fad-97a7-6bf4f38ca780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curiosity         663\n",
       "neutral           184\n",
       "admiration        166\n",
       "approval          130\n",
       "fear               87\n",
       "love               81\n",
       "excitement         79\n",
       "surprise           72\n",
       "sadness            71\n",
       "joy                67\n",
       "confusion          63\n",
       "remorse            59\n",
       "annoyance          56\n",
       "optimism           53\n",
       "anger              47\n",
       "caring             44\n",
       "amusement          43\n",
       "disapproval        43\n",
       "disappointment     36\n",
       "gratitude          34\n",
       "disgust            34\n",
       "embarrassment      19\n",
       "realization        15\n",
       "desire             14\n",
       "nervousness         9\n",
       "relief              5\n",
       "grief               2\n",
       "pride               1\n",
       "Name: ref_emotion, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df.ref_emotion.apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6bc4aa13-59b1-4310-8910-e080a8a5f4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral           300\n",
       "sadness           222\n",
       "excitement        153\n",
       "approval          148\n",
       "joy               140\n",
       "admiration        137\n",
       "disappointment    132\n",
       "nervousness        99\n",
       "curiosity          95\n",
       "fear               79\n",
       "realization        71\n",
       "anger              68\n",
       "love               64\n",
       "surprise           54\n",
       "annoyance          52\n",
       "desire             51\n",
       "caring             44\n",
       "optimism           43\n",
       "embarrassment      36\n",
       "disapproval        36\n",
       "gratitude          28\n",
       "amusement          23\n",
       "disgust            23\n",
       "confusion          22\n",
       "grief              20\n",
       "relief             14\n",
       "remorse            13\n",
       "pride              10\n",
       "Name: chatgpt_emotional_response, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmpDG_results_df.chatgpt_emotional_response.apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ab2ff-464e-4326-880c-c38c6a56a135",
   "metadata": {},
   "source": [
    "# Now calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9cdb2-97b6-4fcf-b93d-e95ea7ad334d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb48de-d92e-4954-ab44-38b87353444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "eccd8ef8-c1c6-4878-8345-49de942ea35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {'admiration': 'positive', 'amusement': 'positive', 'anger': 'negative', 'annoyance': 'negative', 'approval': 'positive', 'caring': 'positive', 'confusion': 'ambiguous', 'curiosity': 'ambiguous', 'desire': 'positive', 'disappointment': 'negative', 'disapproval': 'negative', 'disgust': 'negative', 'embarrassment': 'negative', 'excitement': 'positive', 'fear': 'negative', 'gratitude': 'positive', 'grief': 'negative', 'joy': 'positive', 'love': 'positive', 'nervousness': 'negative', 'optimism': 'positive', 'pride': 'positive', 'realization': 'ambiguous', 'relief': 'positive', 'remorse': 'negative', 'sadness': 'negative', 'surprise': 'ambiguous', 'neutral': 'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e633d-92d8-493c-8173-7e086daa813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4591c88a-b3d1-45c3-a0bc-27ad81f7d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2713"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EmpDG_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "4a56dcbd-0656-405c-8ebc-f506c62289d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_response_no_emotion.apply(lambda x: \"as an AI language model\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b01347d6-cee6-41ac-9393-b1cb2623413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.ref_emotion.apply(lambda x: \"curiosity\" not in x)]\n",
    "## also when the user asks questions\n",
    "#EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_emotional_response.apply(lambda x: \"neutral\" not in x[0])]\n",
    "#EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_emotional_response_emotion.apply(lambda x: \"curiosity\" not in x)]\n",
    "#EmpDG_results_df = EmpDG_results_df[EmpDG_results_df.chatgpt_response_no_emotion_emotion.apply(lambda x: \"curiosity\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1a795e2e-b446-4eb7-9f45-f0dae3150d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2713"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EmpDG_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866b7ee0-193b-4d09-83eb-ec762d690670",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_categories = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "       'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "       'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "       'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "       'relief', 'remorse', 'sadness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "13c95ec0-2e28-464a-ad7a-6873d5245e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1e992_row1_col1, #T_1e992_row5_col2, #T_1e992_row5_col3, #T_1e992_row6_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1e992_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col3\" >F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row0\" class=\"row_heading level0 row0\" >transformer</th>\n",
       "      <td id=\"T_1e992_row0_col0\" class=\"data row0 col0\" >15.040000</td>\n",
       "      <td id=\"T_1e992_row0_col1\" class=\"data row0 col1\" >17.740000</td>\n",
       "      <td id=\"T_1e992_row0_col2\" class=\"data row0 col2\" >7.200000</td>\n",
       "      <td id=\"T_1e992_row0_col3\" class=\"data row0 col3\" >5.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row1\" class=\"row_heading level0 row1\" >emoprepend</th>\n",
       "      <td id=\"T_1e992_row1_col0\" class=\"data row1 col0\" >15.040000</td>\n",
       "      <td id=\"T_1e992_row1_col1\" class=\"data row1 col1\" >18.150000</td>\n",
       "      <td id=\"T_1e992_row1_col2\" class=\"data row1 col2\" >7.720000</td>\n",
       "      <td id=\"T_1e992_row1_col3\" class=\"data row1 col3\" >5.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row2\" class=\"row_heading level0 row2\" >moel</th>\n",
       "      <td id=\"T_1e992_row2_col0\" class=\"data row2 col0\" >15.590000</td>\n",
       "      <td id=\"T_1e992_row2_col1\" class=\"data row2 col1\" >16.960000</td>\n",
       "      <td id=\"T_1e992_row2_col2\" class=\"data row2 col2\" >7.520000</td>\n",
       "      <td id=\"T_1e992_row2_col3\" class=\"data row2 col3\" >5.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row3\" class=\"row_heading level0 row3\" >empDG_woD</th>\n",
       "      <td id=\"T_1e992_row3_col0\" class=\"data row3 col0\" >13.710000</td>\n",
       "      <td id=\"T_1e992_row3_col1\" class=\"data row3 col1\" >17.190000</td>\n",
       "      <td id=\"T_1e992_row3_col2\" class=\"data row3 col2\" >7.850000</td>\n",
       "      <td id=\"T_1e992_row3_col3\" class=\"data row3 col3\" >5.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row4\" class=\"row_heading level0 row4\" >empDG</th>\n",
       "      <td id=\"T_1e992_row4_col0\" class=\"data row4 col0\" >15.190000</td>\n",
       "      <td id=\"T_1e992_row4_col1\" class=\"data row4 col1\" >14.920000</td>\n",
       "      <td id=\"T_1e992_row4_col2\" class=\"data row4 col2\" >7.870000</td>\n",
       "      <td id=\"T_1e992_row4_col3\" class=\"data row4 col3\" >6.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row5\" class=\"row_heading level0 row5\" >chatgpt_response_no_emotion</th>\n",
       "      <td id=\"T_1e992_row5_col0\" class=\"data row5 col0\" >28.640000</td>\n",
       "      <td id=\"T_1e992_row5_col1\" class=\"data row5 col1\" >13.190000</td>\n",
       "      <td id=\"T_1e992_row5_col2\" class=\"data row5 col2\" >14.140000</td>\n",
       "      <td id=\"T_1e992_row5_col3\" class=\"data row5 col3\" >12.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row6\" class=\"row_heading level0 row6\" >chatgpt_emotional_response</th>\n",
       "      <td id=\"T_1e992_row6_col0\" class=\"data row6 col0\" >39.550000</td>\n",
       "      <td id=\"T_1e992_row6_col1\" class=\"data row6 col1\" >14.100000</td>\n",
       "      <td id=\"T_1e992_row6_col2\" class=\"data row6 col2\" >13.350000</td>\n",
       "      <td id=\"T_1e992_row6_col3\" class=\"data row6 col3\" >12.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1e992_level0_row7\" class=\"row_heading level0 row7\" >chatgpt_prompt2_response</th>\n",
       "      <td id=\"T_1e992_row7_col0\" class=\"data row7 col0\" >22.710000</td>\n",
       "      <td id=\"T_1e992_row7_col1\" class=\"data row7 col1\" >10.030000</td>\n",
       "      <td id=\"T_1e992_row7_col2\" class=\"data row7 col2\" >12.230000</td>\n",
       "      <td id=\"T_1e992_row7_col3\" class=\"data row7 col3\" >9.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa19993cb10>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some example data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_classes = 28\n",
    "n_methods = 9\n",
    "classes = [f'class_{i}' for i in range(n_classes)]\n",
    "\n",
    "#true_labels = np.random.choice(classes, size=n_samples)\n",
    "true_labels = EmpDG_results_df[\"ref_emotion\"].apply(lambda x: x[0])\n",
    "#encoder = LabelEncoder()\n",
    "true_labels_encoded = true_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "\n",
    "# Create a DataFrame for each method with predicted labels\n",
    "dfs = []\n",
    "methods = [\"transformer\", \"emoprepend\", \"moel\", \"empDG_woD\", \"empDG\", \"chatgpt_response_no_emotion\", \"chatgpt_emotional_response\", \"chatgpt_prompt2_response\"]\n",
    "#methods = [\"empDG_woD\", \"empDG\", \"chatgpt_response_no_emotion\", \"chatgpt_emotional_response\", \"chatgpt_prompt2_response\"]\n",
    "#for i in range(n_methods):\n",
    "for i, method in enumerate(methods):\n",
    "    #predicted_labels = np.random.choice(classes, size=n_samples)\n",
    "    predicted_labels = EmpDG_results_df[method+\"_emotion\"].apply(lambda x: x[0])\n",
    "    predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "    dfs.append(pd.DataFrame({\n",
    "        'true_labels': true_labels,\n",
    "        f'predicted_labels_{i}': predicted_labels\n",
    "    }))\n",
    "\n",
    "# Define a function to calculate evaluation metrics\n",
    "def evaluate_classification(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "# Calculate evaluation metrics for each method\n",
    "results = {}\n",
    "for i, df in enumerate(dfs):\n",
    "    #method_name = f'Method {i}'\n",
    "    method_name = methods[i]    \n",
    "    predicted_labels = df[f'predicted_labels_{i}']\n",
    "    predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).values\n",
    "    #predicted_labels_encoded = encoder.transform(predicted_labels)\n",
    "    metrics = evaluate_classification(true_labels_encoded, predicted_labels_encoded)\n",
    "    for metric, score in metrics.items():\n",
    "        results.setdefault(metric, {})[method_name] = \"{:.2f}\".format(score*100)\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.astype(float)\n",
    "results_df = results_df.style.apply(highlight_max)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "dd6e4f9a-f50c-4ba7-becf-c12c6259a4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e602e_row1_col1, #T_e602e_row5_col0, #T_e602e_row5_col2, #T_e602e_row5_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e602e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col3\" >F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row0\" class=\"row_heading level0 row0\" >transformer</th>\n",
       "      <td id=\"T_e602e_row0_col0\" class=\"data row0 col0\" >15.850000</td>\n",
       "      <td id=\"T_e602e_row0_col1\" class=\"data row0 col1\" >17.530000</td>\n",
       "      <td id=\"T_e602e_row0_col2\" class=\"data row0 col2\" >6.850000</td>\n",
       "      <td id=\"T_e602e_row0_col3\" class=\"data row0 col3\" >5.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row1\" class=\"row_heading level0 row1\" >emoprepend</th>\n",
       "      <td id=\"T_e602e_row1_col0\" class=\"data row1 col0\" >15.670000</td>\n",
       "      <td id=\"T_e602e_row1_col1\" class=\"data row1 col1\" >18.350000</td>\n",
       "      <td id=\"T_e602e_row1_col2\" class=\"data row1 col2\" >6.970000</td>\n",
       "      <td id=\"T_e602e_row1_col3\" class=\"data row1 col3\" >5.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row2\" class=\"row_heading level0 row2\" >moel</th>\n",
       "      <td id=\"T_e602e_row2_col0\" class=\"data row2 col0\" >17.690000</td>\n",
       "      <td id=\"T_e602e_row2_col1\" class=\"data row2 col1\" >17.870000</td>\n",
       "      <td id=\"T_e602e_row2_col2\" class=\"data row2 col2\" >7.750000</td>\n",
       "      <td id=\"T_e602e_row2_col3\" class=\"data row2 col3\" >6.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row3\" class=\"row_heading level0 row3\" >empDG_woD</th>\n",
       "      <td id=\"T_e602e_row3_col0\" class=\"data row3 col0\" >15.590000</td>\n",
       "      <td id=\"T_e602e_row3_col1\" class=\"data row3 col1\" >16.900000</td>\n",
       "      <td id=\"T_e602e_row3_col2\" class=\"data row3 col2\" >7.620000</td>\n",
       "      <td id=\"T_e602e_row3_col3\" class=\"data row3 col3\" >5.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row4\" class=\"row_heading level0 row4\" >empDG</th>\n",
       "      <td id=\"T_e602e_row4_col0\" class=\"data row4 col0\" >17.140000</td>\n",
       "      <td id=\"T_e602e_row4_col1\" class=\"data row4 col1\" >14.890000</td>\n",
       "      <td id=\"T_e602e_row4_col2\" class=\"data row4 col2\" >7.860000</td>\n",
       "      <td id=\"T_e602e_row4_col3\" class=\"data row4 col3\" >6.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row5\" class=\"row_heading level0 row5\" >chatgpt_response_no_emotion</th>\n",
       "      <td id=\"T_e602e_row5_col0\" class=\"data row5 col0\" >22.340000</td>\n",
       "      <td id=\"T_e602e_row5_col1\" class=\"data row5 col1\" >13.090000</td>\n",
       "      <td id=\"T_e602e_row5_col2\" class=\"data row5 col2\" >12.790000</td>\n",
       "      <td id=\"T_e602e_row5_col3\" class=\"data row5 col3\" >11.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row6\" class=\"row_heading level0 row6\" >chatgpt_emotional_response</th>\n",
       "      <td id=\"T_e602e_row6_col0\" class=\"data row6 col0\" >19.760000</td>\n",
       "      <td id=\"T_e602e_row6_col1\" class=\"data row6 col1\" >10.730000</td>\n",
       "      <td id=\"T_e602e_row6_col2\" class=\"data row6 col2\" >9.440000</td>\n",
       "      <td id=\"T_e602e_row6_col3\" class=\"data row6 col3\" >8.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e602e_level0_row7\" class=\"row_heading level0 row7\" >chatgpt_prompt2_response</th>\n",
       "      <td id=\"T_e602e_row7_col0\" class=\"data row7 col0\" >16.330000</td>\n",
       "      <td id=\"T_e602e_row7_col1\" class=\"data row7 col1\" >9.910000</td>\n",
       "      <td id=\"T_e602e_row7_col2\" class=\"data row7 col2\" >11.200000</td>\n",
       "      <td id=\"T_e602e_row7_col3\" class=\"data row7 col3\" >8.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f109c89c190>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some example data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_classes = 28\n",
    "n_methods = 9\n",
    "classes = [f'class_{i}' for i in range(n_classes)]\n",
    "\n",
    "#true_labels = np.random.choice(classes, size=n_samples)\n",
    "true_labels = EmpDG_results_df[\"ref_emotion\"].apply(lambda x: x[0])\n",
    "#encoder = LabelEncoder()\n",
    "true_labels_encoded = true_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "\n",
    "# Create a DataFrame for each method with predicted labels\n",
    "dfs = []\n",
    "methods = [\"transformer\", \"emoprepend\", \"moel\", \"empDG_woD\", \"empDG\", \"chatgpt_response_no_emotion\", \"chatgpt_emotional_response\", \"chatgpt_prompt2_response\"]\n",
    "#methods = [\"empDG_woD\", \"empDG\", \"chatgpt_response_no_emotion\", \"chatgpt_emotional_response\", \"chatgpt_prompt2_response\"]\n",
    "#for i in range(n_methods):\n",
    "for i, method in enumerate(methods):\n",
    "    #predicted_labels = np.random.choice(classes, size=n_samples)\n",
    "    predicted_labels = EmpDG_results_df[method+\"_emotion\"].apply(lambda x: x[0])\n",
    "    predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "    dfs.append(pd.DataFrame({\n",
    "        'true_labels': true_labels,\n",
    "        f'predicted_labels_{i}': predicted_labels\n",
    "    }))\n",
    "\n",
    "# Define a function to calculate evaluation metrics\n",
    "def evaluate_classification(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "# Calculate evaluation metrics for each method\n",
    "results = {}\n",
    "for i, df in enumerate(dfs):\n",
    "    #method_name = f'Method {i}'\n",
    "    method_name = methods[i]    \n",
    "    predicted_labels = df[f'predicted_labels_{i}']\n",
    "    predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).values\n",
    "    #predicted_labels_encoded = encoder.transform(predicted_labels)\n",
    "    metrics = evaluate_classification(true_labels_encoded, predicted_labels_encoded)\n",
    "    for metric, score in metrics.items():\n",
    "        results.setdefault(metric, {})[method_name] = \"{:.2f}\".format(score*100)\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.astype(float)\n",
    "results_df = results_df.style.apply(highlight_max)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "86e60f31-c0f4-4a55-8d3b-d6e48f0a81da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>transformer</th>\n",
       "      <td>41.84</td>\n",
       "      <td>33.50</td>\n",
       "      <td>33.93</td>\n",
       "      <td>29.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emoprepend</th>\n",
       "      <td>43.05</td>\n",
       "      <td>35.12</td>\n",
       "      <td>35.94</td>\n",
       "      <td>31.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moel</th>\n",
       "      <td>44.75</td>\n",
       "      <td>35.62</td>\n",
       "      <td>35.86</td>\n",
       "      <td>33.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empDG_woD</th>\n",
       "      <td>42.61</td>\n",
       "      <td>34.40</td>\n",
       "      <td>36.12</td>\n",
       "      <td>33.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empDG</th>\n",
       "      <td>42.02</td>\n",
       "      <td>34.84</td>\n",
       "      <td>36.16</td>\n",
       "      <td>33.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatgpt_response_no_emotion</th>\n",
       "      <td>47.70</td>\n",
       "      <td>35.90</td>\n",
       "      <td>35.39</td>\n",
       "      <td>32.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatgpt_emotional_response</th>\n",
       "      <td>45.96</td>\n",
       "      <td>36.15</td>\n",
       "      <td>33.19</td>\n",
       "      <td>30.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatgpt_prompt2_response</th>\n",
       "      <td>46.63</td>\n",
       "      <td>37.39</td>\n",
       "      <td>36.16</td>\n",
       "      <td>30.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision Recall F1 Score\n",
       "transformer                    41.84     33.50  33.93    29.92\n",
       "emoprepend                     43.05     35.12  35.94    31.86\n",
       "moel                           44.75     35.62  35.86    33.10\n",
       "empDG_woD                      42.61     34.40  36.12    33.19\n",
       "empDG                          42.02     34.84  36.16    33.55\n",
       "chatgpt_response_no_emotion    47.70     35.90  35.39    32.54\n",
       "chatgpt_emotional_response     45.96     36.15  33.19    30.18\n",
       "chatgpt_prompt2_response       46.63     37.39  36.16    30.50"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some example data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_classes = 28\n",
    "n_methods = 9\n",
    "classes = [f'class_{i}' for i in range(n_classes)]\n",
    "\n",
    "#true_labels = np.random.choice(classes, size=n_samples)\n",
    "true_labels = EmpDG_results_df[\"ref_emotion\"].apply(lambda x: x[0]).apply(lambda x: emotion_dict[x])\n",
    "encoder = LabelEncoder()\n",
    "#true_labels_encoded = true_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "true_labels_encoded = encoder.fit_transform(true_labels)\n",
    "\n",
    "# Create a DataFrame for each method with predicted labels\n",
    "dfs = []\n",
    "methods = [\"transformer\", \"emoprepend\", \"moel\", \"empDG_woD\", \"empDG\", \"chatgpt_response_no_emotion\", \"chatgpt_emotional_response\", \"chatgpt_prompt2_response\"]\n",
    "#for i in range(n_methods):\n",
    "for i, method in enumerate(methods):\n",
    "    #predicted_labels = np.random.choice(classes, size=n_samples)\n",
    "    predicted_labels = EmpDG_results_df[method+\"_emotion\"].apply(lambda x: x[0]).apply(lambda x: emotion_dict[x])\n",
    "    #predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).to_list()\n",
    "    predicted_labels_encoded = encoder.transform(predicted_labels)\n",
    "    dfs.append(pd.DataFrame({\n",
    "        'true_labels': true_labels,\n",
    "        f'predicted_labels_{i}': predicted_labels\n",
    "    }))\n",
    "\n",
    "# Define a function to calculate evaluation metrics\n",
    "def evaluate_classification(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "# Calculate evaluation metrics for each method\n",
    "results = {}\n",
    "for i, df in enumerate(dfs):\n",
    "    #method_name = f'Method {i}'\n",
    "    method_name = methods[i]    \n",
    "    predicted_labels = df[f'predicted_labels_{i}']\n",
    "    #predicted_labels_encoded = predicted_labels.apply(lambda x: emotion_categories.index(x)).values\n",
    "    predicted_labels_encoded = encoder.transform(predicted_labels)\n",
    "    metrics = evaluate_classification(true_labels_encoded, predicted_labels_encoded)\n",
    "    for metric, score in metrics.items():\n",
    "        results.setdefault(metric, {})[method_name] = \"{:.2f}\".format(score*100)\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "#results_df = results_df.style.apply(highlight_max)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baa43d-3f24-4a71-b110-d3d489939f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8732b1a8-1e20-472c-ac1b-8d7c41268a18",
   "metadata": {},
   "source": [
    "# Finding the best parameters for the emotional version: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc4a5e-802d-4dbe-b51f-43ed1440651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "from itertools import product\n",
    "\n",
    "# Define the possible values for each hyperparameter\n",
    "smooth_methods = ['exp', 'floor', 'add-k', 'none']\n",
    "smooth_values = [0.1, 1, 10]\n",
    "forces = [True, False]\n",
    "lowercases = [True, False]\n",
    "tokenizes = [None, '13a']\n",
    "effective_orders = [True, False]\n",
    "\n",
    "# Define the reference and hypothesis texts\n",
    "#refs = [['This is a test.', 'Another test sentence.'], ['Reference sentence.']]\n",
    "#hyps = ['This is a test sentence.', 'Sentence that does not match the reference.']\n",
    "\n",
    "# Define a list to store the results of each combination of hyperparameters\n",
    "results = []\n",
    "\n",
    "# Loop over all possible combinations of hyperparameters\n",
    "for smooth_method, smooth_value, force, lowercase, tokenize, use_effective_order in tqdm(product(\n",
    "    smooth_methods, smooth_values, forces, lowercases, tokenizes, effective_orders\n",
    "), total=192):\n",
    "    # Calculate the BLEU score using the current combination of hyperparameters\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, references, smooth_method=smooth_method, smooth_value=smooth_value, force=force, lowercase=lowercase, tokenize=tokenize, use_effective_order=use_effective_order).score\n",
    "\n",
    "    # Add the hyperparameters and the corresponding BLEU score to the results list\n",
    "    results.append({\n",
    "        'smooth_method': smooth_method,\n",
    "        'smooth_value': smooth_value,\n",
    "        'force': force,\n",
    "        'lowercase': lowercase,\n",
    "        'tokenize': tokenize,\n",
    "        'use_effective_order': use_effective_order,\n",
    "        'bleu_score': bleu_score\n",
    "    })\n",
    "\n",
    "# Print the results sorted by descending BLEU score\n",
    "for result in sorted(results, key=lambda x: x['bleu_score'], reverse=True):\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f1ce2-422b-494b-8f22-8fa7d16863de",
   "metadata": {},
   "source": [
    "{'smooth_method': 'add-k', 'smooth_value': 10, 'force': True, 'lowercase': True, 'tokenize': None, 'use_effective_order': True, 'bleu_score': 52.417057590025316}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "6b09d3db-e748-4000-bf31-208f9419e9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh no , what happened ?  ',\n",
       " 'that is so exciting ! i hope it goes well for you !  ',\n",
       " 'what happened ?  ',\n",
       " 'oh no , that is terrible . i hope it is not a big deal with a bit .  ',\n",
       " 'oh no ! that is horrible ! i would have been so upset .  ',\n",
       " 'i am so sorry to hear that . what did you do ?  ',\n",
       " 'that is great ! how old is she ?  ',\n",
       " 'that was nice of you !  ',\n",
       " 'oh no , that is not good . do you have a bad experience ?  ',\n",
       " 'that is great ! i am sure you will be fine .  ']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "98ffc76a-d857-4697-8bfc-c6aee9845ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ouch ! what did you take ? '],\n",
       " ['congrats ! thats so exciting do you fel ok ? '],\n",
       " ['i still think it is , i always get so excited '],\n",
       " ['oh wow that is weird . did you say anything to him ? '],\n",
       " ['were you able to take the plate id ? '],\n",
       " ['oh nice . what kind of candy was it ? '],\n",
       " [\"glad to hear it . i hate hearing about children having tragic childhoods and not being able to just simply be a kid . but at least she 'll have a good perspective and appreciate life more . \"],\n",
       " ['what had he made in the world ? '],\n",
       " ['i am really sorry to hear that . i hope everything is alright . '],\n",
       " ['that is a great way to look at it ']]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6d6e35fb-3e4d-404c-a2e3-1f529e9ff665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press enter to continue to the next row. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['did you suffer any injuries ? ']\n",
      "I'm sorry to hear about your scary experience. It's alarming to think about what could have happened, but I'm glad you're okay.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press enter to continue to the next row. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorry to hear ! do you have any idea about the break up ? did you think about it ? ']\n",
      "It's okay to feel lost and hurt right now. Give yourself time to grieve, take care of yourself, and surround yourself with supportive friends and family.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press enter to continue to the next row. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which concert ? ']\n",
      "Awesome, I hope you have an amazing time!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press enter to continue to the next row. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ugh , those articles always get me too ... : ( what was wrong with her ? ']\n",
      "I'm sorry to hear that. It's important to seek medical treatment when needed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18708/2783388172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEmpDG_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# wait for user input before continuing to the next row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Press enter to continue to the next row.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# print the row information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/electra_cls/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m         )\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/electra_cls/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# iterate through each row using iterrows\n",
    "for idx, row in EmpDG_results_df.iterrows():\n",
    "    # wait for user input before continuing to the next row\n",
    "    input(\"Press enter to continue to the next row.\")\n",
    "    \n",
    "    # print the row information\n",
    "    reference = [row['ref']]\n",
    "    print(reference)\n",
    "    hypothesis = str(row['chatgpt_emotional_response'][2])  # convert to string\n",
    "    print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8281e-01c1-49bb-b877-ca8b5f8f202e",
   "metadata": {},
   "source": [
    "# Emotional ChatEPT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5b823bb9-ffa5-4b32-b8b6-1148819b6d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e088405f1a543e5929bfb006b3f3029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SacreBLEU score: 100.00000000000004\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Calculate the perplexity and SacreBLEU score of the chatbot responses\n",
    "total_loss = 0\n",
    "total_tokens = 0\n",
    "references = []\n",
    "hypotheses = []\n",
    "\n",
    "for _, row in tqdm(EmpDG_results_df.iterrows(), total=len(EmpDG_results_df)):\n",
    "    reference = [row['ref']]\n",
    "    hypothesis = str(row['transformer'])  # convert to string\n",
    "    references.append(reference)\n",
    "    hypotheses.append(hypothesis)\n",
    "    \"\"\"tokens = tokenizer.encode(hypothesis, return_tensors='pt')\n",
    "    loss = model(tokens, labels=tokens).loss\n",
    "    total_loss += loss.item() * len(tokens)\n",
    "    total_tokens += len(tokens)\"\"\"\n",
    "\n",
    "#perplexity = exp(total_loss / total_tokens)\n",
    "#sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references).score\n",
    "sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references, smooth_method='add-k', smooth_value=10, force=True, lowercase=True, use_effective_order=True).score\n",
    "\n",
    "#print(\"Perplexity:\", perplexity)\n",
    "print(\"SacreBLEU score:\", sacrebleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff8825-ae3a-4b8d-8434-decf222851ad",
   "metadata": {},
   "source": [
    "\n",
    "17780/? [2:29:47<00:00, 17.18it/s]\n",
    "Perplexity: 28.021526326887294\n",
    "SacreBLEU score: 70.39848207052137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "83dd2d60-07a1-40df-9695-5794fae811b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b497743d9e4b5ba5889d59c53f2c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SacreBLEU score: 52.417057590025316\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Calculate the perplexity and SacreBLEU score of the chatbot responses\n",
    "total_loss = 0\n",
    "total_tokens = 0\n",
    "references = []\n",
    "hypotheses = []\n",
    "\n",
    "for _, row in tqdm(EmpDG_results_df.iterrows(), total=len(results_df)):\n",
    "    reference = [row['ref']]\n",
    "    hypothesis = str(row['chatgpt_emotional_response'][2])  # convert to string\n",
    "    references.append(reference)\n",
    "    hypotheses.append(hypothesis)\n",
    "    #tokens = tokenizer.encode(hypothesis, return_tensors='pt')\n",
    "    #loss = model(tokens, labels=tokens).loss\n",
    "    #total_loss += loss.item() * len(tokens)\n",
    "    #total_tokens += len(tokens)\n",
    "\n",
    "#perplexity = exp(total_loss / total_tokens)\n",
    "#sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references).score\n",
    "sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references, smooth_method='add-k', smooth_value=10, force=True, lowercase=True, use_effective_order=True).score\n",
    "\n",
    "#print(\"Perplexity:\", perplexity)\n",
    "print(\"SacreBLEU score:\", sacrebleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8b722-ec8e-41a6-b709-26d9065ee164",
   "metadata": {},
   "source": [
    "17780/? [18:57<00:00, 15.08it/s]\n",
    "Perplexity: 26.459359145706088\n",
    "SacreBLEU score: 66.52049901111006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2e17246a-d6e8-4953-8d4b-dc0f0a87faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a0bd75094a41c4b7ffe03d73c3745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 28.021526326887294\n",
      "SacreBLEU score: 74.0599898671159\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Calculate the perplexity and SacreBLEU score of the chatbot responses\n",
    "total_loss = 0\n",
    "total_tokens = 0\n",
    "references = []\n",
    "hypotheses = []\n",
    "\n",
    "for _, row in tqdm(chatept_output.iterrows(), total=len(chatept_output)):\n",
    "    reference = [row['chatgpt_response_no_emotion']]\n",
    "    hypothesis = str(row['chatgpt_emotional_response'])  # convert to string\n",
    "    references.append(reference)\n",
    "    hypotheses.append(hypothesis)\n",
    "    #tokens = tokenizer.encode(hypothesis, return_tensors='pt')\n",
    "    #loss = model(tokens, labels=tokens).loss\n",
    "    #total_loss += loss.item() * len(tokens)\n",
    "    #total_tokens += len(tokens)\n",
    "\n",
    "#perplexity = exp(total_loss / total_tokens)\n",
    "#sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references).score\n",
    "sacrebleu_score = sacrebleu.corpus_bleu(hypotheses, references, smooth_method='add-k', smooth_value=10, force=True, lowercase=True, use_effective_order=True).score\n",
    "\n",
    "print(\"Perplexity:\", perplexity)\n",
    "print(\"SacreBLEU score:\", sacrebleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0e602-1aa8-4ca5-8b51-4c6a8ad8dbcc",
   "metadata": {},
   "source": [
    "17780/? [20:50<00:00, 13.78it/s]\n",
    "Perplexity: 45.450342777853926\n",
    "SacreBLEU score: 56.586356745712415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d3a07-7af4-4234-b5a8-9064618f11fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515be8a2-e8ae-4d45-bfcc-53b1c9be2b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
